{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e204f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ee74df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojte\\AppData\\Local\\Temp\\ipykernel_16820\\1893597020.py:16: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('./IMDB_dataset/IMDB dataset.csv')\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "def remove_stopwords(text, stopwords_set):\n",
    "    output = []\n",
    "    for i in text.split():\n",
    "        word = i.strip().lower()\n",
    "        if word not in stopwords_set and word.isalpha():\n",
    "            output.append(word)\n",
    "    return \" \".join(output)\n",
    "    \n",
    "def process_data(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = remove_stopwords(text, stop)\n",
    "    return text\n",
    "\n",
    "df['review']=df['review'].apply(process_data)\n",
    "\n",
    "df.sentiment.replace(\"positive\" , 1 , inplace = True)\n",
    "df.sentiment.replace(\"negative\" , 0 , inplace = True)\n",
    "\n",
    "def tokenize_and_stem(data):\n",
    "    stem_tokens = []\n",
    "    stemmer = PorterStemmer()\n",
    "    data_tokens = word_tokenize(data)\n",
    "    for word in data_tokens:\n",
    "        stem_word = stemmer.stem(word)\n",
    "        stem_tokens.append(stem_word)\n",
    "    return stem_tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38957eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']\n",
    "Y = df['sentiment']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
    "\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fef5699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(reviews, ys):\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    freqs = {}\n",
    "    for y, review in zip(yslist, reviews):\n",
    "        for word in tokenize_and_stem(review):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6bdb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 74775\n"
     ]
    }
   ],
   "source": [
    "freqs = build_freqs(x_train, y_train)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys() ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6ef33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    h = 1 / (1 + np.exp(-z))\n",
    "    return h\n",
    "\n",
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    for i in range(0, num_iters):\n",
    "        z = np.dot(x,theta)\n",
    "        \n",
    "        h = sigmoid(z)\n",
    "        J = -1./m * (np.dot(y.T, np.log(h)) + np.dot((1-y).T,np.log(1-h)))                                                    \n",
    "\n",
    "        theta = theta - (alpha/m) * np.dot(x.T,(h-y))\n",
    "    J = float(J)\n",
    "        \n",
    "    return J, theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b219ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(review, freqs):\n",
    "\n",
    "    word_l = process_data(review)\n",
    "    word_l = tokenize_and_stem(word_l)\n",
    "    \n",
    "    x = np.zeros((1, 3)) \n",
    "    x[0,0] = 1 \n",
    "    \n",
    "    for word in word_l:\n",
    "        x[0,1] += freqs.get((word, 1),0)\n",
    "        x[0,2] += freqs.get((word, 0),0)\n",
    "    \n",
    "    assert(x.shape == (1, 3))   \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8007f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train.reset_index(drop=True)\n",
    "# x_train = x_train.drop(\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580fb44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000e+00 2.28306e+05 2.76312e+05]]\n"
     ]
    }
   ],
   "source": [
    "tmp1 = extract_features(x_train[1], freqs)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfe87b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(x_train), 3))\n",
    "for i in range(len(x_train)):\n",
    "    X[i, :]= extract_features(x_train[i], freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595ffdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000e+00 1.83212e+05 1.91880e+05]\n",
      " [1.00000e+00 2.28306e+05 2.76312e+05]\n",
      " [1.00000e+00 6.52980e+04 7.17730e+04]\n",
      " ...\n",
      " [1.00000e+00 1.21839e+05 1.48854e+05]\n",
      " [1.00000e+00 2.37357e+05 2.87970e+05]\n",
      " [1.00000e+00 1.95996e+05 2.20790e+05]]\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "Y = y_train.to_numpy(dtype='float')\n",
    "\n",
    "Y = np.reshape(Y, (-1, 1))\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c930dc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.6931471734905965.\n",
      "The resulting vector of weights is [0.0, 0.0, -0.0]\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-20, 20000)\n",
    "print(f\"The cost after training is {J}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6869a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(review, freqs, theta):\n",
    "    x = extract_features(review,freqs)\n",
    "    y_pred = sigmoid(np.dot(x,theta))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f95a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_regression(x_test, y_test, freqs, theta):\n",
    "\n",
    "    y_hat = []\n",
    "    for rev in x_test:\n",
    "        y_pred = predict_review(rev, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            y_hat.append(0)\n",
    "\n",
    "    accuracy = (y_hat==np.squeeze(y_test)).sum()/len(x_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "654c6094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.5000\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(x_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6722d75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.8863505337207406.\n",
      "The resulting vector of weights is [1e-08, 0.0001007, -8.987e-05]\n",
      "Logistic regression model's accuracy = 0.6481\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-10, 20000)\n",
    "print(f\"The cost after training is {J}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")\n",
    "tmp_accuracy = test_logistic_regression(x_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbad83bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojte\\AppData\\Local\\Temp\\ipykernel_16820\\152756309.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  J = -1./m * (np.dot(y.T, np.log(h)) + np.dot((1-y).T,np.log(1-h)))\n",
      "C:\\Users\\wojte\\AppData\\Local\\Temp\\ipykernel_16820\\152756309.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  h = 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is nan.\n",
      "The resulting vector of weights is [4.4e-07, 0.01122994, -0.00988898]\n",
      "Logistic regression model's accuracy = 0.6318\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-8, 20000)\n",
    "print(f\"The cost after training is {J}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")\n",
    "tmp_accuracy = test_logistic_regression(x_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9fecd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojte\\AppData\\Local\\Temp\\ipykernel_16820\\152756309.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  h = 1 / (1 + np.exp(-z))\n",
      "C:\\Users\\wojte\\AppData\\Local\\Temp\\ipykernel_16820\\152756309.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  J = -1./m * (np.dot(y.T, np.log(h)) + np.dot((1-y).T,np.log(1-h)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is nan.\n",
      "The resulting vector of weights is [0.00041329, 11.22550229, -9.88485158]\n",
      "Logistic regression model's accuracy = 0.6316\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-5, 20000)\n",
    "print(f\"The cost after training is {J}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")\n",
    "tmp_accuracy = test_logistic_regression(x_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97edd3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.5878769065125304.\n",
      "The resulting vector of weights is [0.0, 3.069e-05, -2.954e-05]\n",
      "Logistic regression model's accuracy = 0.7010\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-12, 20000)\n",
    "print(f\"The cost after training is {J}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")\n",
    "tmp_accuracy = test_logistic_regression(x_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12e44c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.6926584664943483.\n",
      "The resulting vector of weights is [0.0, 2e-08, -9e-08]\n",
      "Logistic regression model's accuracy = 0.5000\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-15, 20000)\n",
    "print(f\"The cost after training is {J}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")\n",
    "tmp_accuracy = test_logistic_regression(x_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4b8566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.6639210210847599.\n",
      "The resulting vector of weights is [0.0, 5.45e-06, -5.32e-06]\n",
      "Logistic regression model's accuracy = 0.6985\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-13, 20000)\n",
    "print(f\"The cost after training is {J}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")\n",
    "tmp_accuracy = test_logistic_regression(x_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e67d8830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.583345217207419.\n",
      "The resulting vector of weights is [0.0, 3.412e-05, -3.283e-05]\n",
      "Logistic regression model's accuracy = 0.7005\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-12, 25000)\n",
    "print(f\"The cost after training is {J}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")\n",
    "tmp_accuracy = test_logistic_regression(x_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f2910e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.5904363504335174.\n",
      "The resulting vector of weights is [0.0, 2.906e-05, -2.797e-05]\n",
      "Logistic regression model's accuracy = 0.7007\n"
     ]
    }
   ],
   "source": [
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-12, 18000)\n",
    "print(f\"The cost after training is {J}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")\n",
    "tmp_accuracy = test_logistic_regression(x_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21d1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
