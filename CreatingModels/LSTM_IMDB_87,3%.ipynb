{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4079f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, LSTM, Flatten, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68c8b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojte\\AppData\\Local\\Temp\\ipykernel_4524\\3305172804.py:15: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('./IMDB_dataset/IMDB dataset.csv')\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "def remove_stopwords(text, stopwords_set):\n",
    "    output = []\n",
    "    for i in text.split():\n",
    "        word = i.strip().lower()\n",
    "        if word not in stopwords_set and word.isalpha():\n",
    "            output.append(word)\n",
    "    return \" \".join(output)\n",
    "    \n",
    "def process_data(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = remove_stopwords(text, stop)\n",
    "    return text\n",
    "\n",
    "df['review']=df['review'].apply(process_data)\n",
    "\n",
    "df.sentiment.replace(\"positive\" , 1 , inplace = True)\n",
    "df.sentiment.replace(\"negative\" , 0 , inplace = True)\n",
    "\n",
    "train, test= train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train, y_train = train['review'], train['sentiment']\n",
    "x_test, y_test = test['review'], test['sentiment']\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,\n",
    "                                             test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e1af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"OOV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25c1828",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(x_train)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e85341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ae401",
   "metadata": {},
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ccaeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 225\n",
    "trunc_type = 'post'\n",
    "oov_tok = 'OOV'\n",
    "padding_type = 'post'\n",
    "vocab_size = len(word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c0c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sequences(sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "test_sentences = tokenizer.texts_to_sequences(x_test)\n",
    "test_padded = pad_sequences(test_sentences, maxlen=max_len, padding=padding_type,truncating=trunc_type)\n",
    "\n",
    "val_sentences = tokenizer.texts_to_sequences(x_val)\n",
    "val_padded = pad_sequences(val_sentences, maxlen=max_len, padding=padding_type,truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6afe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29abf117",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3848abca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 225, 200)          13985200  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 225, 200)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 225, 64)           67840     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 225, 1)            65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,053,105\n",
      "Trainable params: 14,053,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "973ac6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1000/1000 [==============================] - 45s 41ms/step - loss: 0.5712 - accuracy: 0.7000 - val_loss: 0.4494 - val_accuracy: 0.8138\n",
      "Epoch 2/4\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.4152 - accuracy: 0.8203 - val_loss: 0.4126 - val_accuracy: 0.8260\n",
      "Epoch 3/4\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2863 - accuracy: 0.8956 - val_loss: 0.4411 - val_accuracy: 0.8301\n",
      "Epoch 4/4\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3130 - accuracy: 0.8907 - val_loss: 0.5565 - val_accuracy: 0.7788\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "#batch_size = 8\n",
    "history = model.fit(train_padded, y_train, epochs=num_epochs,validation_data=(val_padded, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1513b433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 10ms/step - loss: 0.5464 - accuracy: 0.7823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5464154481887817, 0.7822799682617188]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_padded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30cee269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 225, 600)          41955600  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 225, 600)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 225, 64)           170240    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 14400)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 14401     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,140,241\n",
      "Trainable params: 42,140,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "2000/2000 [==============================] - 154s 76ms/step - loss: 0.3584 - accuracy: 0.8397 - val_loss: 0.3086 - val_accuracy: 0.8706\n",
      "Epoch 2/4\n",
      "2000/2000 [==============================] - 153s 76ms/step - loss: 0.1231 - accuracy: 0.9539 - val_loss: 0.4305 - val_accuracy: 0.8614\n",
      "Epoch 3/4\n",
      "2000/2000 [==============================] - 155s 78ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.6701 - val_accuracy: 0.8533\n",
      "Epoch 4/4\n",
      "2000/2000 [==============================] - 158s 79ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.8336 - val_accuracy: 0.8449\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 600\n",
    "batch_size = 16\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "num_epochs = 4\n",
    "history = model.fit(train_padded, y_train, epochs=num_epochs,batch_size=batch_size, validation_data=(val_padded, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c36019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 10ms/step - loss: 0.7856 - accuracy: 0.8536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7856318950653076, 0.853600025177002]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_padded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4607ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 225, 500)          34963000  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 225, 500)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 225, 128)          322048    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28800)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 28801     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,313,849\n",
      "Trainable params: 35,313,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "1000/1000 [==============================] - 89s 84ms/step - loss: 0.3669 - accuracy: 0.8360 - val_loss: 0.3147 - val_accuracy: 0.8644\n",
      "Epoch 2/4\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.1393 - accuracy: 0.9466 - val_loss: 0.4143 - val_accuracy: 0.8478\n",
      "Epoch 3/4\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0261 - accuracy: 0.9922 - val_loss: 0.6790 - val_accuracy: 0.8486\n",
      "Epoch 4/4\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.9322 - val_accuracy: 0.8479\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 500\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "num_epochs = 4\n",
    "history = model.fit(train_padded, y_train, epochs=num_epochs,batch_size=batch_size, validation_data=(val_padded, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdbf5976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.8662 - accuracy: 0.8531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8662416934967041, 0.8531000018119812]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_padded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf8f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 225, 500)          34963000  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 225, 500)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 225, 256)          775168    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 57600)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 57601     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,795,769\n",
      "Trainable params: 35,795,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "1000/1000 [==============================] - 101s 99ms/step - loss: 0.3681 - accuracy: 0.8337 - val_loss: 0.3154 - val_accuracy: 0.8662\n",
      "Epoch 2/4\n",
      "1000/1000 [==============================] - 99s 99ms/step - loss: 0.1377 - accuracy: 0.9476 - val_loss: 0.4125 - val_accuracy: 0.8537\n",
      "Epoch 3/4\n",
      "1000/1000 [==============================] - 95s 95ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.6548 - val_accuracy: 0.8464\n",
      "Epoch 4/4\n",
      "1000/1000 [==============================] - 95s 95ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.8779 - val_accuracy: 0.8416\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 500\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "num_epochs = 4\n",
    "history = model.fit(train_padded, y_train, epochs=num_epochs,batch_size=batch_size, validation_data=(val_padded, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6778899f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 16ms/step - loss: 0.8572 - accuracy: 0.8433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8571547865867615, 0.8432999849319458]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_padded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "572d400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 225, 800)          55940800  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 225, 800)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 225, 64)           221440    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 14401     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,176,641\n",
      "Trainable params: 56,176,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "4000/4000 [==============================] - 366s 90ms/step - loss: 0.3597 - accuracy: 0.8406 - val_loss: 0.3127 - val_accuracy: 0.8659\n",
      "Epoch 2/4\n",
      "4000/4000 [==============================] - 355s 89ms/step - loss: 0.1087 - accuracy: 0.9599 - val_loss: 0.4468 - val_accuracy: 0.8451\n",
      "Epoch 3/4\n",
      "4000/4000 [==============================] - 369s 92ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.7085 - val_accuracy: 0.8481\n",
      "Epoch 4/4\n",
      "4000/4000 [==============================] - 372s 93ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.9423 - val_accuracy: 0.8395\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 800\n",
    "batch_size = 8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "num_epochs = 4\n",
    "history = model.fit(train_padded, y_train, epochs=num_epochs,batch_size=batch_size, validation_data=(val_padded, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5fbd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 11ms/step - loss: 0.9378 - accuracy: 0.8430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9377745389938354, 0.8429999947547913]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_padded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67652e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 225, 800)          55940800  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 225, 800)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 225, 64)           221440    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 14401     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,176,641\n",
      "Trainable params: 56,176,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1000/1000 [==============================] - 111s 104ms/step - loss: 0.3650 - accuracy: 0.8354 - val_loss: 0.3055 - val_accuracy: 0.8696\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 800\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(train_padded, y_train, epochs=num_epochs,batch_size=batch_size, validation_data=(val_padded, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4581c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 10ms/step - loss: 0.3061 - accuracy: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30613943934440613, 0.8664000034332275]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_padded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e422ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM_86.6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a46e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 225, 800)          55940800  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 225, 800)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 225, 64)           221440    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 28802     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,191,042\n",
      "Trainable params: 56,191,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 800\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acde31ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 106s 101ms/step - loss: 0.3615 - accuracy: 0.8384 - val_loss: 0.3138 - val_accuracy: 0.8695\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert target values to one-hot encoding\n",
    "y_train_encoded = to_categorical(y_train, num_classes=2)\n",
    "y_val_encoded = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "# Update the model.fit() call with the new target values\n",
    "history = model.fit(train_padded, y_train_encoded, epochs=num_epochs, batch_size=batch_size, validation_data=(val_padded, y_val_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5285f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 10ms/step - loss: 0.3089 - accuracy: 0.8730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3088577389717102, 0.8730000257492065]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_encoded = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "model.evaluate(test_padded, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a1e7003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 225)\n",
      "(225,)\n"
     ]
    }
   ],
   "source": [
    "print(test_padded.shape)\n",
    "print(test_padded[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d151d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 225\n",
    "\n",
    "test_input = np.reshape(train_padded[3], (1, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74cf2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87325f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.02311346 0.9768866 ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba6ad32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a6146de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c76151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM_87.3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe457939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"Interesting movie.\"\n",
    "review = tokenizer.texts_to_sequences([review])\n",
    "review = pad_sequences(review, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ac1d646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = np.reshape(review, (1, max_len))\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9494679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.4734102 0.5265899]], shape=(1, 2), dtype=float32)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "output = model(review)\n",
    "print(output)\n",
    "predictions = np.argmax(output, axis=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c3b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
